{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c860647-56fd-4612-ae23-ee851a9370e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1_NF count: 7980934\nQ1_star count: 7980934\nQ1_obt count: 7980934\nQ1_NF ∩ Q1_star ∩ Q1_obt: 7980934\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "Q1_NF = spark.sql('''\n",
    "SELECT DISTINCT part.titleId, \n",
    "  part.personId\n",
    "FROM imdb_dev.silver.Participation as part\n",
    "JOIN imdb_dev.silver.Category as cat on part.categoryId = cat.categoryId\n",
    "WHERE cat.category = 'director' \n",
    "''')\n",
    "\n",
    "Q1_star = spark.sql(''' \n",
    "SELECT DISTINCT part.titleId, \n",
    "  part.personId \n",
    "FROM imdb_dev.gold.ParticipationFact as part\n",
    "JOIN imdb_dev.gold.CategoryDim as cat on part.categoryId = cat.categoryId\n",
    "WHERE cat.category = 'director'\n",
    "''')\n",
    "\n",
    "Q1_obt = spark.sql('''\n",
    "SELECT DISTINCT obt.titleId, \n",
    "  obt.personId \n",
    "FROM imdb_dev.gold.OneBigTable as obt\n",
    "WHERE obt.category = 'director'\n",
    "''')\n",
    "\n",
    "print(\"Q1_NF count:\", Q1_NF.count())\n",
    "print(\"Q1_star count:\", Q1_star.count())\n",
    "print(\"Q1_obt count:\", Q1_obt.count())\n",
    "print(\"Q1_NF ∩ Q1_star ∩ Q1_obt:\", (Q1_NF.intersect(Q1_star).intersect(Q1_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d171e151-33f6-468d-a822-65d8f7fee378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2_NF count: 383644\nQ2_star count: 383644\nQ2_obt count: 383644\nQ2_NF ∩ Q2_star ∩ Q2_obt: 383644\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "Q2_NF = spark.sql('''\n",
    "SELECT DISTINCT tit.primaryTitle, \n",
    "  part.personId, \n",
    "  part.titleId\n",
    "FROM imdb_dev.silver.Participation as part\n",
    "JOIN imdb_dev.silver.Title as tit on part.titleId = tit.titleId\n",
    "WHERE tit.isAdult = TRUE \n",
    "  AND tit.startYear > 2000 \n",
    "  AND tit.endYear < 2010 \n",
    "  AND tit.runtimeMinutes > 10\n",
    "''')\n",
    "\n",
    "Q2_star = spark.sql(''' \n",
    "SELECT DISTINCT tit.primaryTitle, \n",
    "  part.personId, part.titleId\n",
    "FROM imdb_dev.gold.ParticipationFact as part\n",
    "JOIN imdb_dev.gold.TitleDim as tit on tit.titleId = part.titleId\n",
    "WHERE tit.isAdult = TRUE \n",
    "  AND tit.startYear > 2000 \n",
    "  AND tit.endYear < 2010 \n",
    "  AND tit.runtimeMinutes > 10\n",
    "''')\n",
    "\n",
    "Q2_obt = spark.sql('''\n",
    "SELECT DISTINCT obt.primaryTitle, \n",
    "  obt.personId, \n",
    "  obt.titleId\n",
    "FROM imdb_dev.gold.OneBigTable as obt\n",
    "WHERE obt.isAdult = TRUE \n",
    "  AND obt.startYear > 2000 \n",
    "  AND obt.endYear < 2010 \n",
    "  AND obt.runtimeMinutes > 10\n",
    "''')\n",
    "\n",
    "print(\"Q2_NF count:\", Q2_NF.count())\n",
    "print(\"Q2_star count:\", Q2_star.count())\n",
    "print(\"Q2_obt count:\", Q2_obt.count())\n",
    "print(\"Q2_NF ∩ Q2_star ∩ Q2_obt:\", (Q2_NF.intersect(Q2_star).intersect(Q2_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52a5d088-e976-4f04-8083-e66c0f9735bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3_NF count: 1849367\nQ3_star count: 1849367\nQ3_obt count: 1849367\nQ3_NF ∩ Q3_star ∩ Q3_obt: 1849367\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "Q3_NF = spark.sql('''\n",
    "SELECT DISTINCT part.personId, \n",
    "  part.titleId, \n",
    "  tit.primaryTitle, \n",
    "  tit.startYear\n",
    "FROM imdb_dev.silver.Participation as part\n",
    "JOIN imdb_dev.silver.Title as tit on part.titleId = tit.titleId\n",
    "JOIN imdb_dev.silver.GenreOfTitle as got on part.titleId = got.titleId\n",
    "JOIN imdb_dev.silver.Genre as gen on gen.genreId = got.genreId\n",
    "WHERE (gen.genre = 'Comedy') \n",
    "  AND tit.startYear > 2012 \n",
    "  AND tit.runtimeMinutes > 60\n",
    "''')\n",
    "\n",
    "Q3_star = spark.sql(''' \n",
    "SELECT DISTINCT pf.personId, \n",
    "  pf.titleId, \n",
    "  td.primaryTitle, \n",
    "  td.startYear\n",
    "FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "JOIN imdb_dev.gold.TitleDim AS td ON pf.titleId = td.titleId\n",
    "JOIN imdb_dev.gold.GenreBridge AS gb ON pf.titleId = gb.titleId\n",
    "JOIN imdb_dev.gold.GenreDim AS gd ON gb.genreId = gd.genreId\n",
    "WHERE gd.genre = 'Comedy'\n",
    "  AND td.startYear > 2012\n",
    "  AND td.runtimeMinutes > 60\n",
    "\n",
    "''')\n",
    "\n",
    "Q3_obt = spark.sql('''\n",
    "SELECT DISTINCT obt.personId, \n",
    "  obt.titleId, \n",
    "  obt.primaryTitle, \n",
    "  obt.startYear\n",
    "FROM imdb_dev.gold.OneBigTable as obt\n",
    "WHERE obt.genre = 'Comedy'\n",
    "  AND obt.startYear > 2012\n",
    "  AND obt.runtimeMinutes > 60\n",
    "''')\n",
    "\n",
    "print(\"Q3_NF count:\", Q3_NF.count())\n",
    "print(\"Q3_star count:\", Q3_star.count())\n",
    "print(\"Q3_obt count:\", Q3_obt.count())\n",
    "print(\"Q3_NF ∩ Q3_star ∩ Q3_obt:\", (Q3_NF.intersect(Q3_star).intersect(Q3_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b79d32-79c5-44b0-b0a8-99d98bf5f433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4_NF count: 797972\nQ4_star count: 797972\nQ4_obt count: 797972\nQ4_NF ∩ Q4_star ∩ Q4_obt: 797972\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "Q4_NF = spark.sql('''\n",
    "SELECT uq_parts.personId, \n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating\n",
    "FROM \n",
    "(\n",
    "  SELECT DISTINCT part.personId,\n",
    "    part.titleId,\n",
    "    rat.averageRating\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN imdb_dev.silver.TitleRating as rat on part.titleId = rat.titleId\n",
    "  WHERE rat.numVotes > 200\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "''')\n",
    "\n",
    "Q4_star = spark.sql(''' \n",
    "SELECT uq_parts.personId, \n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.personId,\n",
    "    pf.titleId,\n",
    "    pf.averageRating\n",
    "  FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  WHERE pf.numVotes > 200\n",
    "    AND pf.averageRating IS NOT NULL\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "''')\n",
    "\n",
    "Q4_obt = spark.sql('''\n",
    "SELECT deduped_obt.personId, \n",
    "  ROUND(avg(CAST(deduped_obt.averageRating AS FLOAT)), 1) as average_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT obt.personId, \n",
    "  obt.titleId, \n",
    "  obt.averageRating, \n",
    "  obt.numVotes\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.numVotes > 200\n",
    "    AND obt.averageRating IS NOT NULL\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.personId\n",
    "''')\n",
    "\n",
    "print(\"Q4_NF count:\", Q4_NF.count())\n",
    "print(\"Q4_star count:\", Q4_star.count())\n",
    "print(\"Q4_obt count:\", Q4_obt.count())\n",
    "print(\"Q4_NF ∩ Q4_star ∩ Q4_obt:\", (Q4_NF.intersect(Q4_star).intersect(Q4_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c91df363-73a3-471d-afa6-2375948ad03b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5_NF count: 552210\nQ5_star count: 552210\nQ5_obt count: 552210\nQ5_NF ∩ Q5_star ∩ Q5_obt: 552210\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "Q5_NF = spark.sql('''\n",
    "SELECT uq_parts.personId, \n",
    "  uq_parts.parentTitleId, \n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  ROUND(min(CAST(uq_parts.averageRating AS FLOAT)), 1) as minimum_rating,\n",
    "  ROUND(max(CAST(uq_parts.averageRating AS FLOAT)), 1) as maximum_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT part.personId,\n",
    "    part.titleId,\n",
    "    ep.parentTitleId,\n",
    "    rat.averageRating\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN imdb_dev.silver.TitleEpisode as ep on part.titleId = ep.titleId \n",
    "  JOIN imdb_dev.silver.TitleRating as rat on part.titleId = rat.titleId\n",
    "  WHERE rat.numVotes > 100\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId, uq_parts.parentTitleId\n",
    "''')\n",
    "\n",
    "Q5_star = spark.sql(''' \n",
    "SELECT uq_parts.personId,\n",
    "  uq_parts.parentTitleId,\n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  ROUND(min(CAST(uq_parts.averageRating AS FLOAT)), 1) as minimum_rating,\n",
    "  ROUND(max(CAST(uq_parts.averageRating AS FLOAT)), 1) as maximum_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.personId,\n",
    "    pf.titleId,\n",
    "    pf.parentTitleId,\n",
    "    pf.averageRating\n",
    "  FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  WHERE pf.numVotes > 100\n",
    "    AND pf.parentTitleId IS NOT NULL\n",
    "    AND pf.averageRating IS NOT NULL\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId, uq_parts.parentTitleId\n",
    "''')\n",
    "\n",
    "Q5_obt = spark.sql('''\n",
    "SELECT deduped_obt.personId, \n",
    "  deduped_obt.parentTitleId,\n",
    "  ROUND(avg(CAST(deduped_obt.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  ROUND(min(CAST(deduped_obt.averageRating AS FLOAT)), 1) as minimum_rating,\n",
    "  ROUND(max(CAST(deduped_obt.averageRating AS FLOAT)), 1) as maximum_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT obt.personId, \n",
    "    obt.titleId, \n",
    "    obt.parentTitleId, \n",
    "    obt.averageRating, \n",
    "    obt.numVotes\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.numVotes > 100\n",
    "    AND obt.parentTitleId IS NOT NULL\n",
    "    AND obt.averageRating IS NOT NULL\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.personId, deduped_obt.parentTitleId\n",
    "''')\n",
    "\n",
    "print(\"Q5_NF count:\", Q5_NF.count())\n",
    "print(\"Q5_star count:\", Q5_star.count())\n",
    "print(\"Q5_obt count:\", Q5_obt.count())\n",
    "print(\"Q5_NF ∩ Q5_star ∩ Q5_obt:\", (Q5_NF.intersect(Q5_star).intersect(Q5_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78f8b4e-5571-40fc-8f6a-57f930f4f391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6_NF count: 140098\nQ6_star count: 140098\nQ6_obt count: 140098\nQ6_NF ∩ Q6_star ∩ Q6_obt: 140098\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "Q6_NF = spark.sql('''\n",
    "SELECT uq_parts.personId, \n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  ROUND(min(CAST(uq_parts.averageRating AS FLOAT)), 1) as minimum_rating,\n",
    "  ROUND(max(CAST(uq_parts.averageRating AS FLOAT)), 1) as maximum_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT part.personId,\n",
    "  part.titleId,\n",
    "  rat.averageRating\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN imdb_dev.silver.Title as tit on part.titleId = tit.titleId\n",
    "  JOIN imdb_dev.silver.TitleRating as rat on tit.titleId = rat.titleId\n",
    "  JOIN imdb_dev.silver.GenreOfTitle as got on part.titleId = got.titleId\n",
    "  JOIN imdb_dev.silver.Genre as gen on gen.genreId = got.genreId\n",
    "  WHERE (gen.genre = \"Romance\") \n",
    "    AND tit.startYear > 2012 \n",
    "    AND tit.runtimeMinutes BETWEEN 60 AND 150\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "ORDER BY average_rating DESC\n",
    "''')\n",
    "\n",
    "Q6_star = spark.sql(''' \n",
    "SELECT uq_parts.personId,\n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  ROUND(min(CAST(uq_parts.averageRating AS FLOAT)), 1) as minimum_rating,\n",
    "  ROUND(max(CAST(uq_parts.averageRating AS FLOAT)), 1) as maximum_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.personId,\n",
    "  pf.titleId,\n",
    "  pf.averageRating\n",
    "  FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  JOIN imdb_dev.gold.TitleDim AS td ON pf.titleId = td.titleId\n",
    "  JOIN imdb_dev.gold.GenreBridge AS gb ON pf.titleId = gb.titleId\n",
    "  JOIN imdb_dev.gold.GenreDim AS gd ON gb.genreId = gd.genreId\n",
    "  WHERE gd.genre = 'Romance'\n",
    "    AND td.startYear > 2012\n",
    "    AND td.runtimeMinutes BETWEEN 60 AND 150\n",
    "    AND pf.averageRating IS NOT NULL\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "ORDER BY average_rating DESC\n",
    "''')\n",
    "\n",
    "Q6_obt = spark.sql('''\n",
    "SELECT deduped_obt.personId, \n",
    "  ROUND(avg(CAST(deduped_obt.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  ROUND(min(CAST(deduped_obt.averageRating AS FLOAT)), 1) as minimum_rating,\n",
    "  ROUND(max(CAST(deduped_obt.averageRating AS FLOAT)), 1) as maximum_rating\n",
    "FROM (\n",
    "  SELECT DISTINCT obt.personId, \n",
    "    obt.titleId, \n",
    "    obt.averageRating\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.genre = 'Romance'\n",
    "    AND obt.startYear > 2012\n",
    "    AND obt.runtimeMinutes BETWEEN 60 AND 150\n",
    "    AND obt.averageRating IS NOT NULL\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.personId\n",
    "ORDER BY average_rating DESC\n",
    "''')\n",
    "\n",
    "print(\"Q6_NF count:\", Q6_NF.count())\n",
    "print(\"Q6_star count:\", Q6_star.count())\n",
    "print(\"Q6_obt count:\", Q6_obt.count())\n",
    "print(\"Q6_NF ∩ Q6_star ∩ Q6_obt:\", (Q6_NF.intersect(Q6_star).intersect(Q6_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e3eaffe-2969-424e-ac72-fd097a9df49c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q7_NF count: 373627\nQ7_star count: 373627\nQ7_obt count: 373627\nQ7_NF ∩ Q7_star ∩ Q7_obt: 373627\n"
     ]
    }
   ],
   "source": [
    "#Q7\n",
    "Q7_NF = spark.sql('''\n",
    "WITH relevant_titles AS (\n",
    "  SELECT DISTINCT got.titleId\n",
    "  FROM imdb_dev.silver.GenreOfTitle AS got\n",
    "  JOIN imdb_dev.silver.Genre AS gen ON gen.genreId = got.genreId\n",
    "  WHERE gen.genre IN ('Comedy', 'Romance')  \n",
    ")\n",
    "\n",
    "SELECT uq_parts.personId, \n",
    "  SUM(CAST(uq_parts.averageRating * uq_parts.numVotes AS FLOAT)) / SUM(CAST(uq_parts.numVotes AS FLOAT)) AS weighted_average, \n",
    "  COUNT(uq_parts.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT part.personId,\n",
    "    part.titleId,\n",
    "    rat.averageRating,\n",
    "    rat.numVotes\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN relevant_titles as revtit on part.titleId = revtit.titleId\n",
    "  JOIN imdb_dev.silver.TitleRating as rat on part.titleId = rat.titleId\n",
    "  JOIN imdb_dev.silver.Title AS tit ON tit.titleId = part.titleId\n",
    "  WHERE tit.startYear BETWEEN 2000 AND 2020\n",
    "    AND tit.runtimeMinutes BETWEEN 45 AND 100\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "ORDER BY weighted_average DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "Q7_star = spark.sql(''' \n",
    "WITH relevant_titles AS (\n",
    "  SELECT DISTINCT gb.titleId\n",
    "  FROM imdb_dev.gold.GenreBridge AS gb\n",
    "  JOIN imdb_dev.gold.GenreDim AS gd ON gb.genreId = gd.genreId\n",
    "  WHERE gd.genre IN ('Comedy', 'Romance')\n",
    ")\n",
    "\n",
    "SELECT uq_parts.personId,\n",
    "  SUM(CAST(uq_parts.averageRating * uq_parts.numVotes AS FLOAT)) / SUM(CAST(uq_parts.numVotes AS FLOAT)) AS weighted_average,\n",
    "  COUNT(uq_parts.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.titleId,\n",
    "    pf.personId,\n",
    "    pf.averageRating,\n",
    "    pf.numVotes\n",
    "  FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  JOIN relevant_titles AS rt ON pf.titleId = rt.titleId\n",
    "  JOIN imdb_dev.gold.TitleDim AS td ON pf.titleId = td.titleId\n",
    "  WHERE td.startYear BETWEEN 2000 AND 2020\n",
    "    AND td.runtimeMinutes BETWEEN 45 AND 100\n",
    "    AND pf.averageRating is not NULL\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "ORDER BY weighted_average DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "Q7_obt = spark.sql('''\n",
    "SELECT \n",
    "  deduped_obt.personId, \n",
    "  SUM(CAST(deduped_obt.averageRating * deduped_obt.numVotes AS FLOAT)) / SUM(CAST(deduped_obt.numVotes AS FLOAT)) AS weighted_average,\n",
    "  COUNT(deduped_obt.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT obt.personId, \n",
    "    obt.titleId, \n",
    "    obt.averageRating, \n",
    "    obt.numVotes\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.genre IN ('Comedy', 'Romance')\n",
    "    AND obt.startYear BETWEEN 2000 AND 2020\n",
    "    AND obt.runtimeMinutes BETWEEN 45 AND 100\n",
    "    AND obt.averageRating is not NULL\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.personId\n",
    "ORDER BY weighted_average DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "print(\"Q7_NF count:\", Q7_NF.count())\n",
    "print(\"Q7_star count:\", Q7_star.count())\n",
    "print(\"Q7_obt count:\", Q7_obt.count())\n",
    "print(\"Q7_NF ∩ Q7_star ∩ Q7_obt:\", (Q7_NF.intersect(Q7_star).intersect(Q7_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc39c72-ced6-40df-8356-3d3bd119e117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q8_NF count: 2145\nQ8_star count: 2145\nQ8_obt count: 2145\nQ8_NF ∩ Q8_star ∩ Q8_obt: 2145\n"
     ]
    }
   ],
   "source": [
    "#Q8\n",
    "Q8_NF = spark.sql('''\n",
    "WITH relevant_titles AS (\n",
    "  SELECT DISTINCT got.titleId\n",
    "  FROM imdb_dev.silver.GenreOfTitle AS got\n",
    "  JOIN imdb_dev.silver.Genre AS gen ON gen.genreId = got.genreId\n",
    "  WHERE gen.genre IN ('Sci-Fi', 'Fantasy', 'Adventure', 'Action')  \n",
    ")\n",
    "\n",
    "SELECT uq_parts.personId, \n",
    "  SUM(CAST(uq_parts.averageRating * uq_parts.numVotes AS FLOAT)) / SUM(CAST(uq_parts.numVotes AS FLOAT)) AS weighted_average, \n",
    "  COUNT(uq_parts.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT part.personId,\n",
    "    part.titleId,\n",
    "    rat.averageRating,\n",
    "    rat.numVotes\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN relevant_titles as revtit on part.titleId = revtit.titleId\n",
    "  JOIN imdb_dev.silver.TitleRating as rat on part.titleId = rat.titleId\n",
    "  JOIN imdb_dev.silver.Title AS tit ON tit.titleId = part.titleId\n",
    "  JOIN imdb_dev.silver.TitleType AS typ ON tit.titleTypeId = typ.titleTypeId\n",
    "  WHERE (typ.titleType = 'movie' or typ.titleType = 'tvSeries')\n",
    "    AND tit.startYear > 1980\n",
    "    AND tit.endYear < 2000\n",
    "    AND tit.runtimeMinutes > 300\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "HAVING (SUM(uq_parts.averageRating * uq_parts.numVotes) / SUM(uq_parts.numVotes)) > 5.0\n",
    "ORDER BY weighted_average DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "Q8_star = spark.sql(''' \n",
    "WITH relevant_titles AS (\n",
    "  SELECT DISTINCT gb.titleId\n",
    "  FROM imdb_dev.gold.GenreBridge AS gb\n",
    "  JOIN imdb_dev.gold.GenreDim AS gd ON gb.genreId = gd.genreId\n",
    "  WHERE gd.genre IN ('Sci-Fi', 'Fantasy', 'Adventure', 'Action')\n",
    ")\n",
    "\n",
    "SELECT uq_parts.personId,\n",
    "  SUM(CAST(uq_parts.averageRating * uq_parts.numVotes AS FLOAT)) / SUM(CAST(uq_parts.numVotes AS FLOAT)) AS weighted_average,\n",
    "  COUNT(uq_parts.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.personId,\n",
    "    pf.titleId,\n",
    "    pf.averageRating,\n",
    "    pf.numVotes\n",
    "    FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  JOIN relevant_titles AS rt ON pf.titleId = rt.titleId\n",
    "  JOIN imdb_dev.gold.TitleDim AS td ON pf.titleId = td.titleId\n",
    "  WHERE td.titleType IN ('movie', 'tvSeries')\n",
    "    AND td.startYear > 1980\n",
    "    AND td.endYear < 2000\n",
    "    AND td.runtimeMinutes > 300\n",
    "    AND pf.averageRating is not NULL\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "HAVING (SUM(uq_parts.averageRating * uq_parts.numVotes) / SUM(uq_parts.numVotes)) > 5.0\n",
    "ORDER BY weighted_average DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "Q8_obt = spark.sql('''\n",
    "SELECT \n",
    "  deduped_obt.personId, \n",
    "  SUM(CAST(deduped_obt.averageRating * deduped_obt.numVotes AS FLOAT)) / SUM(CAST(deduped_obt.numVotes AS FLOAT)) AS weighted_average,\n",
    "  COUNT(deduped_obt.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT obt.personId, obt.titleId, obt.averageRating, obt.numVotes\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.genre IN ('Sci-Fi', 'Fantasy', 'Adventure', 'Action')\n",
    "    AND obt.titleType IN ('movie', 'tvSeries')\n",
    "    AND obt.startYear > 1980\n",
    "    AND obt.endYear < 2000\n",
    "    AND obt.runtimeMinutes > 300\n",
    "    AND obt.averageRating is not NULL\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.personId\n",
    "HAVING SUM(deduped_obt.averageRating * deduped_obt.numVotes) / SUM(deduped_obt.numVotes) > 5.0\n",
    "ORDER BY weighted_average DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "print(\"Q8_NF count:\", Q8_NF.count())\n",
    "print(\"Q8_star count:\", Q8_star.count())\n",
    "print(\"Q8_obt count:\", Q8_obt.count())\n",
    "print(\"Q8_NF ∩ Q8_star ∩ Q8_obt:\", (Q8_NF.intersect(Q8_star).intersect(Q8_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78e47fdb-1ad9-4329-9c14-a4c78c3f1348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q9_NF count: 1497\nQ9_star count: 1497\nQ9_obt count: 1497\nQ9_NF ∩ Q9_star ∩ Q9_obt: 1497\n"
     ]
    }
   ],
   "source": [
    "#Q9\n",
    "Q9_NF = spark.sql('''\n",
    "WITH relevant_participations AS (\n",
    "  SELECT DISTINCT prim.personId, kn.titleId\n",
    "  FROM imdb_dev.silver.PersonPrimaryProfession AS prim\n",
    "  JOIN imdb_dev.silver.Profession AS per ON prim.professionId = per.professionId\n",
    "  JOIN imdb_dev.silver.KnownForParticipation AS kn ON prim.personId = kn.personId\n",
    "  JOIN imdb_dev.silver.Participation AS part ON part.personId = kn.personId and kn.titleId = part.titleId\n",
    "  WHERE per.profession IN ('director', 'writer', 'producer')  \n",
    ")\n",
    "\n",
    "SELECT uq_parts.personId, \n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  COUNT(uq_parts.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT part.personId,\n",
    "    part.titleId,\n",
    "    rat.averageRating\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN relevant_participations as revpart on part.titleId = revpart.titleId and part.personId = revpart.personId\n",
    "  JOIN imdb_dev.silver.TitleRating as rat on part.titleId = rat.titleId\n",
    "  JOIN imdb_dev.silver.Title AS tit ON tit.titleId = part.titleId\n",
    "  JOIN imdb_dev.silver.TitleType AS typ ON tit.titleTypeId = typ.titleTypeId\n",
    "  WHERE typ.titleType = 'short'\n",
    "    AND tit.startYear > 1900\n",
    "    AND tit.endYear < 2000\n",
    "    AND tit.runtimeMinutes > 3\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "HAVING COUNT(uq_parts.titleId) > 1\n",
    "  AND AVG(uq_parts.averageRating) > 6.0\n",
    "ORDER BY average_rating DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "Q9_star = spark.sql(''' \n",
    "WITH relevant_participations AS (\n",
    "  SELECT DISTINCT ppb.personId, pf.titleId\n",
    "  FROM imdb_dev.gold.PrimaryProfessionBridge AS ppb\n",
    "  JOIN imdb_dev.gold.PrimaryProfessionDim AS ppd ON ppb.professionId = ppd.professionId\n",
    "  JOIN imdb_dev.gold.ParticipationFact AS pf ON pf.personId = ppb.personId\n",
    "  WHERE ppd.profession IN ('director', 'writer', 'producer')  \n",
    "  AND pf.isKnownForParticipation = true\n",
    ")\n",
    "\n",
    "SELECT uq_parts.personId,\n",
    "  ROUND(avg(CAST(uq_parts.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  COUNT(uq_parts.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.personId,\n",
    "    pf.titleId,\n",
    "    pf.averageRating\n",
    "  FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  JOIN relevant_participations AS rp ON pf.personId = rp.personId AND pf.titleId = rp.titleId\n",
    "  JOIN imdb_dev.gold.TitleDim AS td ON pf.titleId = td.titleId\n",
    "  WHERE td.titleType = 'short'\n",
    "    AND td.startYear > 1900\n",
    "    AND td.endYear < 2000\n",
    "    AND td.runtimeMinutes > 3\n",
    "    AND pf.averageRating is not NULL\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.personId\n",
    "HAVING COUNT(uq_parts.titleId) > 1\n",
    "  AND AVG(uq_parts.averageRating) > 6.0\n",
    "ORDER BY average_rating DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "Q9_obt = spark.sql('''\n",
    "SELECT \n",
    "  deduped_obt.personId, \n",
    "  ROUND(avg(CAST(deduped_obt.averageRating AS FLOAT)), 1) as average_rating,\n",
    "  COUNT(deduped_obt.titleId) AS titles_count\n",
    "FROM (\n",
    "  SELECT DISTINCT obt.personId, obt.titleId, obt.averageRating\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.profession IN ('director', 'writer', 'producer')\n",
    "    AND obt.isKnownForParticipation = TRUE\n",
    "    AND obt.titleType = 'short'\n",
    "    AND obt.startYear > 1900\n",
    "    AND obt.endYear < 2000\n",
    "    AND obt.runtimeMinutes > 3\n",
    "    AND obt.averageRating is not NULL\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.personId\n",
    "HAVING COUNT(deduped_obt.titleId) > 1\n",
    "   AND AVG(deduped_obt.averageRating) > 6.0\n",
    "ORDER BY average_rating DESC, titles_count DESC\n",
    "''')\n",
    "\n",
    "print(\"Q9_NF count:\", Q9_NF.count())\n",
    "print(\"Q9_star count:\", Q9_star.count())\n",
    "print(\"Q9_obt count:\", Q9_obt.count())\n",
    "print(\"Q9_NF ∩ Q9_star ∩ Q9_obt:\", (Q9_NF.intersect(Q9_star).intersect(Q9_obt)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6059af57-55fd-413e-b0c8-36837f23a166",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q10_NF count: 6798\nQ10_star count: 6798\nQ10_obt count: 6798\nQ10_NF ∩ Q10_star ∩ Q10_obt: 6798\n"
     ]
    }
   ],
   "source": [
    "#Q10\n",
    "Q10_NF = spark.sql('''\n",
    "WITH relevant_participations AS (\n",
    "  SELECT DISTINCT prim.personId, kn.titleId\n",
    "  FROM imdb_dev.silver.PersonPrimaryProfession AS prim\n",
    "  JOIN imdb_dev.silver.KnownForParticipation AS kn ON prim.personId = kn.personId\n",
    "  JOIN imdb_dev.silver.Profession AS per ON prim.professionId = per.professionId\n",
    "  JOIN imdb_dev.silver.Participation AS part ON part.personId = kn.personId and kn.titleId = part.titleId\n",
    "  WHERE per.profession IN ('actor', 'producer')  \n",
    "),\n",
    "relevant_titles AS (\n",
    "  SELECT DISTINCT akas.titleId\n",
    "  FROM imdb_dev.silver.TitleAKAS AS akas\n",
    "  JOIN imdb_dev.silver.Region AS reg ON akas.regionId = reg.regionId\n",
    "  WHERE reg.region IN ('US', 'GB')\n",
    ")\n",
    "\n",
    "SELECT uq_parts.titleId, \n",
    "  COUNT(uq_parts.personId) AS num_actors_producers\n",
    "FROM (\n",
    "  SELECT DISTINCT part.personId,\n",
    "    part.titleId\n",
    "  FROM imdb_dev.silver.Participation as part\n",
    "  JOIN relevant_participations as revpart on part.titleId = revpart.titleId and part.personId = revpart.personId\n",
    "  JOIN relevant_titles as revtit on part.titleId = revtit.titleId\n",
    "  JOIN imdb_dev.silver.TitleRating as rat on part.titleId = rat.titleId\n",
    "  JOIN imdb_dev.silver.Title AS tit ON tit.titleId = part.titleId\n",
    "  JOIN imdb_dev.silver.TitleType AS typ ON tit.titleTypeId = typ.titleTypeId\n",
    "  JOIN imdb_dev.silver.Category as cat on part.categoryId = cat.categoryId\n",
    "  WHERE (typ.titleType = 'short' or typ.titleType = 'tvSeries')\n",
    "    AND (cat.category = 'actor' or cat.category = 'producer')\n",
    "    AND rat.averageRating > 3.0\n",
    "    AND rat.numVotes > 100\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.titleId\n",
    "HAVING COUNT(uq_parts.personId) BETWEEN 3 and 10\n",
    "ORDER BY num_actors_producers DESC\n",
    "''')\n",
    "\n",
    "Q10_star = spark.sql(''' \n",
    "WITH relevant_participations AS (\n",
    "  SELECT DISTINCT ppb.personId, pf.titleId\n",
    "  FROM imdb_dev.gold.PrimaryProfessionBridge AS ppb\n",
    "  JOIN imdb_dev.gold.PrimaryProfessionDim AS ppd ON ppb.professionId = ppd.professionId\n",
    "  JOIN imdb_dev.gold.ParticipationFact AS pf ON ppb.personId = pf.personId\n",
    "  WHERE ppd.profession IN ('actor', 'producer')\n",
    "    AND pf.isKnownForParticipation = TRUE\n",
    "),\n",
    "relevant_titles AS (\n",
    "  SELECT DISTINCT ab.titleId\n",
    "  FROM imdb_dev.gold.AKASBridge AS ab\n",
    "  JOIN imdb_dev.gold.AKASDim AS ad ON ab.AKASId = ad.AKASId\n",
    "  WHERE ad.region IN ('US', 'GB')\n",
    ")\n",
    "\n",
    "SELECT uq_parts.titleId,\n",
    "  COUNT(uq_parts.personId) AS num_actors_producers\n",
    "FROM (\n",
    "  SELECT DISTINCT pf.personId,\n",
    "    pf.titleId\n",
    "  FROM imdb_dev.gold.ParticipationFact AS pf\n",
    "  JOIN relevant_participations AS rp ON pf.titleId = rp.titleId AND pf.personId = rp.personId\n",
    "  JOIN relevant_titles AS rt ON pf.titleId = rt.titleId\n",
    "  JOIN imdb_dev.gold.TitleDim AS td ON pf.titleId = td.titleId\n",
    "  JOIN imdb_dev.gold.CategoryDim AS cd ON pf.categoryId = cd.categoryId\n",
    "  WHERE td.titleType IN ('short', 'tvSeries')\n",
    "    AND cd.category IN ('actor', 'producer')\n",
    "    AND pf.averageRating > 3.0\n",
    "    AND pf.numVotes > 100\n",
    ") as uq_parts\n",
    "GROUP BY uq_parts.titleId\n",
    "HAVING COUNT(uq_parts.personId) BETWEEN 3 AND 10\n",
    "ORDER BY num_actors_producers DESC\n",
    "''')\n",
    "\n",
    "Q10_obt = spark.sql('''\n",
    "SELECT \n",
    "  deduped_obt.titleId, \n",
    "  COUNT(deduped_obt.personId) AS num_actors_producers\n",
    "FROM (\n",
    "  SELECT DISTINCT titleId, \n",
    "    personId\n",
    "  FROM imdb_dev.gold.OneBigTable as obt\n",
    "  WHERE obt.profession IN ('actor', 'producer')\n",
    "    AND obt.isKnownForParticipation = TRUE\n",
    "    AND obt.region IN ('US', 'GB')\n",
    "    AND obt.titleType IN ('short', 'tvSeries')\n",
    "    AND obt.category IN ('actor', 'producer')\n",
    "    AND obt.averageRating > 3.0\n",
    "    AND obt.numVotes > 100\n",
    ") AS deduped_obt\n",
    "GROUP BY deduped_obt.titleId\n",
    "HAVING COUNT(deduped_obt.personId) BETWEEN 3 AND 10\n",
    "ORDER BY num_actors_producers DESC\n",
    "''')\n",
    "\n",
    "print(\"Q10_NF count:\", Q10_NF.count())\n",
    "print(\"Q10_star count:\", Q10_star.count())\n",
    "print(\"Q10_obt count:\", Q10_obt.count())\n",
    "print(\"Q10_NF ∩ Q10_star ∩ Q10_obt:\", (Q10_NF.intersect(Q10_star).intersect(Q10_obt)).count())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "validate sql experiments",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}