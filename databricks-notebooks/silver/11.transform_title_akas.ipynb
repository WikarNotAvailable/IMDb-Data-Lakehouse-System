{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f10ae218-c6ce-4994-8032-78de5c5e5509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, when, split, col, explode\n",
    "from pyspark.sql.types import StringType\n",
    "import uuid\n",
    "                           \n",
    "def generate_uuid():\n",
    "    return str(uuid.uuid4())\n",
    "uuid_udf = udf(generate_uuid, StringType())\n",
    "\n",
    "df = spark.read.table(\"imdb_dev.bronze.title_akas\") \n",
    "#99.4% attributes, 69.3% types,  33.1% languages, 22.5% region \n",
    "\n",
    "df_title_AKAS = (\n",
    "    df.select(\"titleId\", \"title\", \"region\", \"types\")\n",
    "    .filter(col(\"region\") != \"\\\\N\")\n",
    "    .withColumn(\"titleAKASId\", uuid_udf())\n",
    "    .withColumn(\"types\", when(col(\"types\") == \"\\\\N\", \"Unknown\").otherwise(col(\"types\")))\n",
    "    .withColumn(\"types\", split(\"types\", \"\\u0002\"))\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015a7b1d-71e2-4eb9-b8cd-d52c65de5c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_region = (\n",
    "    df.select(\"region\")\n",
    "    .distinct()\n",
    "    .withColumn(\"regionId\", uuid_udf())\n",
    ")\n",
    "df_region = df_region.select(\"regionId\", \"region\")\n",
    "df_region.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.Region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e22697b-b84f-43be-8c18-ad22d3277c6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_type_AKAS = (\n",
    "    df_title_AKAS.select(explode(\"types\").alias(\"typeAKAS\"))\n",
    "    .distinct()\n",
    "    .withColumn(\"typeAKASId\", uuid_udf())\n",
    ")\n",
    "df_type_AKAS = df_type_AKAS.select(\"typeAKASId\", \"typeAKAS\")\n",
    "df_type_AKAS.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.TypeAKAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0453256-1a84-41a3-908c-e94aa1be5773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_type_AKAS = spark.read.table(\"imdb_dev.silver.TypeAKAS\") \n",
    "\n",
    "df_type_of_alternative = (\n",
    "    df_title_AKAS.select(\"titleAKASId\", explode(\"types\").alias(\"typeAKAS\"))\n",
    "    .join(df_type_AKAS, on=\"typeAKAS\", how=\"left\")\n",
    "    .drop(\"typeAKAS\")\n",
    ")\n",
    "df_type_of_alternative.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.TypeOfAlternative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b25c829-62fd-480a-8a80-51aa4196d9e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_region = spark.read.table(\"imdb_dev.silver.Region\") \n",
    "\n",
    "df_title_AKAS = (\n",
    "    df_title_AKAS.join(df_region, on=\"region\", how=\"left\")\n",
    "    .drop(\"region\", \"types\")\n",
    ")\n",
    "df_title_AKAS = df_title_AKAS.select(\"titleAKASId\", \"titleId\", \"title\", \"regionId\")\n",
    "df_title_AKAS.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.TitleAKAS\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11.transform_title_akas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}