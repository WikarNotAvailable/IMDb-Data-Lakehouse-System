{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29fc1061-cdb7-4b04-bc1c-f27886038131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split, udf, when, col, regexp_extract, mean, stddev, lit\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "def generate_uuid():\n",
    "    return str(uuid.uuid4())\n",
    "uuid_udf = udf(generate_uuid, StringType())\n",
    "\n",
    "def random_birth_year(mean_val, std_val):\n",
    "    return int(random.normalvariate(mean_val, std_val))\n",
    "random_birth_year_udf = udf(random_birth_year, IntegerType())\n",
    "\n",
    "def random_lifespan(mean_life, std_life):\n",
    "    lifespan = int(random.normalvariate(mean_life, std_life))\n",
    "    return max(lifespan, 35)\n",
    "random_lifespan_udf = udf(random_lifespan, IntegerType())\n",
    "\n",
    "df = spark.read.table(\"imdb_dev.bronze.name_basics\")\n",
    "df = ( \n",
    "    df.withColumnRenamed(\"nconst\", \"personId\")\n",
    "    .withColumn(\"primaryProfession\", split(\"primaryProfession\", \",\"))\n",
    "    .withColumn(\"knownForTitles\", split(\"knownForTitles\", \",\"))\n",
    "    .withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "    .withColumn(\"deathYear\", col(\"deathYear\").cast(\"int\"))\n",
    "    .filter((col(\"primaryName\") != \"\\\\N\")) #53 records removed\n",
    ")\n",
    "\n",
    "stats = df.select(mean(\"birthYear\").alias(\"mean\"), stddev(\"birthYear\").alias(\"stddev\")).collect()[0]\n",
    "mean_birth = stats[\"mean\"]\n",
    "std_birth = stats[\"stddev\"]\n",
    "\n",
    "df_lifespan = (\n",
    "    df.filter(col(\"deathYear\").isNotNull() & col(\"birthYear\").isNotNull()) \n",
    "    .withColumn(\"lifespan\", col(\"deathYear\") - col(\"birthYear\"))\n",
    ")\n",
    "stats = df_lifespan.select(mean(\"lifespan\").alias(\"mean\"), stddev(\"lifespan\").alias(\"stddev\")).collect()[0]\n",
    "mean_lifespan = stats[\"mean\"]\n",
    "std_lifespan = stats[\"stddev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b92131-557f-421d-8afb-fccfa3c2a596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_professions = (\n",
    "    df.select(explode(\"primaryProfession\").alias(\"profession\"))\n",
    "    .distinct()\n",
    "    .withColumn(\"professionId\", uuid_udf())\n",
    "    .withColumn(\"profession\", when(col(\"profession\") == \"\\\\N\", \"Other\").otherwise(col(\"profession\")))\n",
    ")\n",
    "df_professions = df_professions.select(\"professionId\", \"profession\")\n",
    "df_professions.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.Profession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f0fb3fe-4abf-48af-b53f-94acb4f05333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_professions = spark.read.table(\"imdb_dev.silver.Profession\")\n",
    "\n",
    "df_person_primary_professions = (\n",
    "    df.select(\"personId\", explode(\"primaryProfession\").alias(\"profession\"))\n",
    "    .withColumn(\"profession\", when(col(\"profession\") == \"\\\\N\", \"Other\").otherwise(col(\"profession\")))\n",
    "    .join(df_professions, on=\"profession\", how=\"left\")\n",
    "    .drop(\"profession\")\n",
    ") \n",
    "df_person_primary_professions.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.PersonPrimaryProfession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865fe4b8-98d5-4d65-959d-95a15ff4ae0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_known_for_titles = df.select([\"personId\", explode(\"knownForTitles\").alias(\"titleId\")])\n",
    "df_known_for_titles.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.KnownForParticipation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92eacd78-fb97-4a9f-806a-b407c69b0a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_person = (\n",
    "    df.withColumnRenamed(\"nconst\", \"personId\")\n",
    "    .withColumnRenamed(\"primaryName\", \"personName\")\n",
    "    .withColumn(\"birthYear\", when(col(\"birthYear\").isNull(), random_birth_year_udf(lit(mean_birth), lit(std_birth))).otherwise(col(\"birthYear\")))\n",
    "    .withColumn(\"deathYear\", when(col(\"deathYear\").isNull(), col(\"birthYear\") + random_lifespan_udf(lit(mean_lifespan), lit(std_lifespan))).otherwise(col(\"deathYear\")))\n",
    "    .withColumn(\"deathYear\", when(col(\"deathYear\") > lit(2024), None).otherwise(col(\"deathYear\")))\n",
    "    .drop(\"primaryProfession\", \"knownForTitles\")    \n",
    ") #95.5 % of birth and 98.3% of death are missing values, normally columns should be dropped but I filled them with normal distribution of existing values for research purposes\n",
    "df_person.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.Person\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "6.transform_name_basics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
