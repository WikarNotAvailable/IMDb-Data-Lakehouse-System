{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22827e9c-8f9e-4d1a-a7bd-fc4b1b861545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, when, col, regexp_extract\n",
    "from pyspark.sql.types import StringType\n",
    "import uuid\n",
    "\n",
    "def generate_uuid():\n",
    "    return str(uuid.uuid4())\n",
    "uuid_udf = udf(generate_uuid, StringType())\n",
    "\n",
    "df_participation = spark.read.table(\"imdb_dev.bronze.title_principals\")\n",
    "\n",
    "df_person_deleted = spark.read.table(\"imdb_dev.bronze.name_basics\")\n",
    "df_person_deleted = df_person_deleted.filter((col(\"primaryName\") == \"\\\\N\"))\n",
    "\n",
    "#81% of jobs empty therefore column dropped, 51% characters empty due to being not applicable - set to \"Unnamed Background Character\"\n",
    "df_participation = (\n",
    "    df_participation.drop(\"job\", \"ordering\")\n",
    "    .withColumn(\"participationId\", uuid_udf())\n",
    "    .join(df_person_deleted.select(\"nconst\"), on=\"nconst\", how=\"left_anti\")\n",
    "    .withColumnRenamed(\"tconst\", \"titleId\")\n",
    "    .withColumnRenamed(\"nconst\", \"personId\")\n",
    "    .withColumnRenamed(\"characters\", \"characterName\")\n",
    "    .withColumn(\"characterName\", when(col(\"characterName\") == \"\\\\N\", '[\"Unnamed Background Character\"]').otherwise(col(\"characterName\")))\n",
    "    .withColumn(\"characterName\", regexp_extract(col(\"characterName\"), r'\"\\s*([^\"]+)\\s*\"', 1))\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1523c2e-483e-4b6b-8719-1a5958637d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_category = (\n",
    "    df_participation.select(\"category\")\n",
    "    .distinct()\n",
    "    .withColumn(\"categoryId\", uuid_udf())\n",
    ")\n",
    "df_category = df_category.select(\"categoryId\", \"category\")\n",
    "df_category.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3b439c-9b53-4a2e-a361-03cb5103ad5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_category = spark.read.table(\"imdb_dev.silver.Category\")\n",
    "\n",
    "df_participation = (\n",
    "    df_participation.join(df_category, on=\"category\", how=\"left\")\n",
    "    .drop(\"category\")\n",
    ")\n",
    "df_participation = df_participation.select(\"participationId\", \"titleId\", \"personId\", \"categoryId\", \"characterName\")\n",
    "df_participation.write.format(\"delta\").mode(\"overwrite\").insertInto(\"imdb_dev.silver.Participation\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "7.transform_title_principals",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
