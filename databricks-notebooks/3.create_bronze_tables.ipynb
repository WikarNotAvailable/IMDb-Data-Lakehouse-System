{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ad5620-ad03-4c83-8aca-24d6968672fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today_str = \"27-05-2025\" #datetime.today().strftime('%d-%m-%Y')\n",
    "\n",
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.name_basics\n",
    "(\n",
    " nconst STRING,\n",
    " primaryName STRING,\n",
    " birthYear INT,\n",
    " deathYear INT,\n",
    " primaryProfession STRING,\n",
    " knownForTitles STRING\n",
    ")\n",
    "USING CSV\n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/name.basics.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221abfc0-c85d-451f-8e19-a36a20a86613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.name_basics\n",
    "(\n",
    " nconst STRING,\n",
    " primaryName STRING,\n",
    " birthYear INT,\n",
    " deathYear INT,\n",
    " primaryProfession STRING,\n",
    " knownForTitles STRING\n",
    ")\n",
    "USING CSV\n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/name.basics.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16bc9ab2-e815-4554-bc1f-0bbbe1120edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.title_ratings\n",
    "(\n",
    "  tconst STRING,\n",
    "  averageRating FLOAT,\n",
    "  numVotes INT\n",
    ")\n",
    "USING CSV \n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/title.ratings.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b5774b1-1d12-4a71-8332-67b7fb813251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.title_principals\n",
    "(\n",
    "  tconst STRING,\n",
    "  ordering INT,\n",
    "  nconst STRING,\n",
    "  category STRING,\n",
    "  job STRING,\n",
    "  characters STRING\n",
    ")\n",
    "USING CSV \n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/title.principals.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bd74d37-f160-4522-a71d-a897b8fada1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.title_episode\n",
    "(\n",
    "  tconst STRING,\n",
    "  parentTconst STRING,\n",
    "  seasonNumber INT,\n",
    "  episodeNumber INT\n",
    ")\n",
    "USING CSV \n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/title.episode.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4fa968-b289-4bab-959a-7ad4eec620e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.title_basics\n",
    "(\n",
    "  tconst STRING,\n",
    "  titleType STRING,\n",
    "  primaryTitle STRING,\n",
    "  originalTitle STRING,\n",
    "  isAdult STRING,\n",
    "  startYear INT,\n",
    "  endYear INT,\n",
    "  runtimeMinutes INT,\n",
    "  genres STRING\n",
    ")\n",
    "USING CSV \n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/title.basics.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7989e709-2d62-4c66-a24b-7ae39c0e3c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS imdb_dev.bronze.title_akas\n",
    "(\n",
    "  titleId STRING,\n",
    "  ordering INT,\n",
    "  title STRING,\n",
    "  region STRING,\n",
    "  language STRING,\n",
    "  types STRING,\n",
    "  attributes STRING,\n",
    "  isOriginalTitle BOOLEAN\n",
    ")\n",
    "USING CSV \n",
    "OPTIONS (\n",
    "  path \"abfss://bronze@storageaccimdbdl.dfs.core.windows.net/{today_str}/title.akas.tsv\",\n",
    "  header \"true\",\n",
    "  delimiter '\\t'\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.create_bronze_tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}